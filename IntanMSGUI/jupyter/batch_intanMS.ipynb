{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import struct\n",
    "import json\n",
    "import datetime\n",
    "import scipy\n",
    "import scipy.signal\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "notebook_path = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "# the code path is two folders up from this notebook + /code\n",
    "core_path = os.path.dirname(notebook_path)\n",
    "basepath = os.path.dirname(os.path.dirname(notebook_path))\n",
    "\n",
    "sys.path.append(core_path)\n",
    "sys.path.append(basepath)\n",
    "\n",
    "from core.readMDA import readMDA, get_Fs\n",
    "from core.Tint_Matlab import int16toint8\n",
    "from core.tetrode_conversion import convert_tetrode, is_tetrode, batch_basename_tetrodes, \\\n",
    "batch_add_tetrode_headers, get_tetrode_parameters, write_tetrode_header \n",
    "from core.convert_position import convert_position\n",
    "from core.eeg_conversion import convert_eeg, get_eeg_channels\n",
    "from core.utils import find_sub, session_datetime\n",
    "from core.intan2mda import intan2mda, get_reref_data\n",
    "from core.mdaSort import sort_intan\n",
    "from core.set_conversion import convert_setfile, get_session_parameters\n",
    "from core.rhd_utils import intan_scalar, tetrode_map, tintRef2intan, intanRef2tint\n",
    "from core.intan_rhd_functions import rhd_duration, find_basename_files, read_data, read_header, \\\n",
    "get_data_limits, is_session_beginning, get_probe_name, get_ref_index\n",
    "from core.intan_mountainsort import validate_session, convert_intan_mountainsort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters You Can Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTERPOLATE\n",
    "interpolation=True  # if you want to interpolate, options: True or False, remember capital letter\n",
    "interpolation=False\n",
    "if interpolation:\n",
    "    desired_Fs = int(48e3)  # Sampling Frequency you will interpolate to\n",
    "else:\n",
    "    desired_Fs = int(24e3)\n",
    "\n",
    "# WHITEN\n",
    "whiten = 'true'  # if you want to whiten or not, 'true' or 'false', lower case letters\n",
    "# whiten = 'false'\n",
    "\n",
    "# THRESHOLD\n",
    "flip_sign=True # if you want to flip the signal (multiply by -1)\n",
    "# remember if flip_sign is true then the negative troughs become peaks, so you should\n",
    "# do detect_sign = 1\n",
    "detect_interval = 10  # it will split up the data into segments of this value and find a peak/trough for each segment\n",
    "detect_sign = 1  # 0 = positive and negative peaks, 1 = positive peaks, -1 = negative peaks\n",
    "\n",
    "if whiten == 'true':\n",
    "    detect_threshold = 3.5  # the threshold of the data, if whitened, data is normalized to standard deviations, so a value of 3\n",
    "    # would mean 3 standard deviations away from baseline. If not whitened treat it like a Tint threshold, i.e. X bits. \n",
    "    # essentially bits vs standard deviations.\n",
    "else:\n",
    "    # you can grab a value from a set file with this animal, the parameter is called 'threshold', it is however in\n",
    "    # 16bit, so divide the value by 256 to convert to 8bit, since the thresholding is in 8 bit.\n",
    "    detect_threshold = 33\n",
    "    \n",
    "# BANDPASS\n",
    "freq_min = 300  # min frequency to bandpass at\n",
    "freq_max = 7000  # max freq to bandpass at\n",
    "\n",
    "# EEG Settings\n",
    "\n",
    "eeg_channels = 'first'  # this will save the 1st channel as an .eeg in each tetrode\n",
    "# eeg_channels = 'all'  # this will save all the channels as their own .eeg file\n",
    "# eeg_channels = [W, X, Y, Z]  # list of channels if you want to specify which ones to use\n",
    "\n",
    "#MASK\n",
    "mask=True\n",
    "\n",
    "masked_chunk_size = None  # The amount of indices that you will segment for masking artifacts. \n",
    "# if you leave as None it will use a value of Fs/10 or Fs/20, I forget\n",
    "\n",
    "mask_num_write_chunks = 100  # this is how many of the chunk segments will be written at the same time, mainly just for\n",
    "# optimizing write speeds, just try to leave it as ~100k - 300k samples.\n",
    "\n",
    "mask_threshold = 6  # number of standard deviations the Root of the Sum of the Squares (RSS) of all the segments \n",
    "# (of masked chunk size). If the RSS is above this threshold it will assume it is artifact, and set all values in this\n",
    "# segment to zero.\n",
    "\n",
    "# software re-ref PARAMETERS (essentially software re-referencing)\n",
    "software_rereference = True  # if you want to remove the common signal (mean values) \n",
    "# between channels, set to True, otherwise False\n",
    "\n",
    "# reref_method=None\n",
    "reref_method = 'sd'  # methods of which to remove signal, 'sd' will caculate the standard deviation of every channel\n",
    "# and choose the channels with the two lowest values and remove those signals from the rest (the 2nd lowest will be removed\n",
    "# from the 1st lowest). Somewhat like what you guys do visually in Axona.\n",
    "\n",
    "reref_channels = 'auto'  # below we have a dictionary of previously chosen values \n",
    "# depending on the mouse\n",
    "# if set to auto, it will choose those values.\n",
    "\n",
    "# reref_channels = [16, 9]  # if you wanted to just say which \n",
    "# channels to subtract from the rest, do it here, \n",
    "# reref_channels = None\n",
    "# it will override the automatic stuff. Essentially look through .set files\n",
    "\n",
    "clip_size = 50  # samples per spike, default 50\n",
    "\n",
    "notch_filter = True  # if you want to add a notch. However, it is already filtered using freq_min, so this doesn't really help\n",
    "# unless of course your freqmin is below 60 Hz, default False\n",
    "\n",
    "positionSampleFreq = 50  # sampling frequency of position, default 50\n",
    "\n",
    "pre_spike_samples = 15  # number of samples pre-threshold samples to take, default 10\n",
    "post_spike_samples = 35  # number of post threshold samples to take, default 40\n",
    "\n",
    "if pre_spike_samples + post_spike_samples != clip_size:\n",
    "    raise ValueError(\n",
    "        \"the pre (%d) and post (%d) spike samples need to add up to the clip_size: %d.\" % (\n",
    "            pre_spike_samples, post_spike_samples, int(clip_size)))\n",
    "\n",
    "# Axona Artifact Rejection Criteria, I'd just leave these. They are in the manual\n",
    "rejthreshtail = 43  #  I think, the latter 20-30% can't be above this value ( I think)\n",
    "rejstart = 30  #\n",
    "rejthreshupper = 100  # if 1st sample is above this value in bits, it will discard\n",
    "rejthreshlower = -100  # if 1st sample is below this value in bits, it will discard\n",
    "\n",
    "# The percentage of spikes to remove as outliers, this will make it so they don't make the majority of the \n",
    "# spikes look really small in amplitude\n",
    "remove_outliers = True  # if False, it won't remove outliers, if True, it will.\n",
    "remove_spike_percentage = 5  # percent value, default 1, haven't experimented much with this\n",
    "\n",
    "remove_method = 'max'  # this will find the max of the peak values (or min if it's negative)\n",
    "# and set that as the clipping value\n",
    "\n",
    "clip_scalar = 1.05\n",
    "# clip_scalar = 1  # this will multiply the clipping value found via the remove_method method, \n",
    "# and then scale by this value.\n",
    "\n",
    "# feature parameters\n",
    "num_features = 10\n",
    "max_num_clips_for_pca = 1000\n",
    "\n",
    "# miscellaneous\n",
    "self=None  # this is code jargin for object oriented programming, mainly used for GUI's, we don't need this\n",
    "# just needs to be set in the function so I have it set to None."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directory To Analyze\n",
    "change directory parameter, remember to use **double slash** instead of **slash \\**, because windows sucks sometimes. This will only populate basenames (the first file for each session, contains the time value of zero)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7 .rhd sessions in this directory!\n"
     ]
    }
   ],
   "source": [
    "# remember to use \\\\ instead of \\\n",
    "\n",
    "# directory = 'H:\\\\data\\\\VirtualMazeData\\\\b6_august_18_2\\\\SimpleCircularTrack'\n",
    "# directory = 'H:\\\\data\\\\VirtualMazeData\\\\b6_august_18_2\\\\LinearTrack'\n",
    "\n",
    "# directory = 'H:\\\\data\\\\VirtualMazeData\\\\b6_august_18_1\\\\LinearTrack'\n",
    "# directory = 'H:\\\\data\\\\VirtualMazeData\\\\b6_august_18_1\\\\SimpleCircularTrack'\n",
    "\n",
    "# directory = 'E:\\\\Apollo_D_Drive\\\\data\\\\VirtualMazeData\\\\ANT1_2\\\\ParallelLinearGlobalTrack'\n",
    "\n",
    "# directory = 'H:\\\\data\\\\VirtualMazeData\\\\j20_sleep_2\\\\SimpleCircularTrack'\n",
    "\n",
    "# directory = 'H:\\\\data\\\\VirtualMazeData\\\\j20_sleep_1\\\\SimpleCircularTrack'\n",
    "# directory = 'H:\\\\data\\\\VirtualMazeData\\\\j20_sleep_1\\\\LinearTrack'\n",
    "directory = r'E:\\Apollo_D_Drive\\data\\VirtualMazeData\\NT_360a_2\\ParallelLinearGlobalTrack'\n",
    "# directory = r'E:\\Apollo_D_Drive\\data\\VirtualMazeData\\NT_361a_2\\ParallelLinearGlobalTrack'\n",
    "\n",
    "basename_files = [os.path.join(directory, file) for file in os.listdir(directory) if '.rhd' in file if is_session_beginning(os.path.join(directory, file))]\n",
    "\n",
    "print('There are %d .rhd sessions in this directory!' % len(basename_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mouse: NT_360a_2\n"
     ]
    }
   ],
   "source": [
    "mouse = os.path.basename(os.path.dirname(directory))\n",
    "print('mouse: %s' % mouse)\n",
    "\n",
    "# these are TINT channels, \n",
    "# these are 0-based so channel 0 here is channel 1 (or T1Ch1), 1 = T1Ch2, \n",
    "# channel 4 is T2Ch1\n",
    "\n",
    "axona_refs = {\n",
    "    'b6_august_18_1': [4,3],\n",
    "    'b6_august_18_2': [4,3],\n",
    "    'j20_sleep_1' : [4,3],\n",
    "    'j20_sleep_2' : [4,3],\n",
    "    'b6_sep_18_1' : [4,3],\n",
    "    'ANT1_2': [4, 3],\n",
    "    'NT_360a_2': [4, 3],\n",
    "    'NT_361a_2': [4, 3],\n",
    "    'march_19' : [13, 3], \n",
    "    'NT_181': [4, 3],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Analyzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nrhd_file = 'E:\\\\Apollo_D_Drive\\\\data\\\\VirtualMazeData\\\\j20_sleep_1\\\\SimpleCircularTrack\\\\j20_1_simple_circular_190114_145852.rhd'\\noutput_basename = 'E:\\\\Apollo_D_Drive\\\\data\\\\VirtualMazeData\\\\j20_sleep_1\\\\SimpleCircularTrack\\\\j20_1_simple_circular_190114_145852_ms'\\nvalidate_session(rhd_file, output_basename, eeg_channels)\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "rhd_file = 'E:\\\\Apollo_D_Drive\\\\data\\\\VirtualMazeData\\\\j20_sleep_1\\\\SimpleCircularTrack\\\\j20_1_simple_circular_190114_145852.rhd'\n",
    "output_basename = 'E:\\\\Apollo_D_Drive\\\\data\\\\VirtualMazeData\\\\j20_sleep_1\\\\SimpleCircularTrack\\\\j20_1_simple_circular_190114_145852_ms'\n",
    "validate_session(rhd_file, output_basename, eeg_channels)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing file (1/7): NT_360a_2_1000_plgt_190401_154208\n",
      "The following session has already been analyzed, or is missing required files: NT_360a_2_1000_plgt_190401_154208!\n",
      "Analyzing file (2/7): NT_360a_2_1000_plgt_190402_094238\n",
      "The following session has already been analyzed, or is missing required files: NT_360a_2_1000_plgt_190402_094238!\n",
      "Analyzing file (3/7): NT_360a_2_1000_plgt_190402_133222\n",
      "The following session has already been analyzed, or is missing required files: NT_360a_2_1000_plgt_190402_133222!\n",
      "Analyzing file (4/7): NT_360a_2_1000_plgt_190403_103311\n",
      "The following session has already been analyzed, or is missing required files: NT_360a_2_1000_plgt_190403_103311!\n",
      "Analyzing file (5/7): NT_360a_2_1000_plgt_190403_130117\n",
      "The following session has already been analyzed, or is missing required files: NT_360a_2_1000_plgt_190403_130117!\n",
      "Analyzing file (6/7): NT_360a_2_1000_plgt_190404_104359\n",
      "The following session has already been analyzed, or is missing required files: NT_360a_2_1000_plgt_190404_104359!\n",
      "Analyzing file (7/7): NT_360a_2_1000_plgt_190404_135919\n",
      "The following session has already been analyzed, or is missing required files: NT_360a_2_1000_plgt_190404_135919!\n",
      "------finished------\n"
     ]
    }
   ],
   "source": [
    "for i, current_session in enumerate(basename_files):\n",
    "    # grabs session files\n",
    "    \n",
    "    directory = os.path.dirname(current_session)\n",
    "    \n",
    "    tint_basename = os.path.basename(os.path.splitext(current_session)[0])\n",
    "    tint_fullpath = os.path.join(directory, tint_basename)\n",
    "\n",
    "    print('Analyzing file (%d/%d): %s' % (i+1, len(basename_files), tint_basename))\n",
    "    \n",
    "    output_basename = '%s_ms' % tint_fullpath\n",
    " \n",
    "    session_valid = validate_session(current_session, output_basename, eeg_channels, self=self)\n",
    "   \n",
    "    if not session_valid:\n",
    "        print('The following session has already been analyzed, or is missing required files: %s!' % os.path.basename(\n",
    "            tint_fullpath))\n",
    "        continue\n",
    "    \n",
    "    rhd_session_file = os.path.splitext(os.path.basename(current_session))[0]\n",
    "\n",
    "    rhd_basename = rhd_session_file[:find_sub(rhd_session_file, '_')[-2]]\n",
    "\n",
    "    session_files = find_basename_files(rhd_basename, directory)\n",
    "\n",
    "    rhd_session_fullfile = os.path.join(directory, rhd_session_file + '.rhd')\n",
    "\n",
    "    # find the session with our rhd file in it\n",
    "    session_files = [sub_list for sub_list in session_files if rhd_session_fullfile in sub_list][0]\n",
    "\n",
    "    if type(session_files) != list:\n",
    "        # if there is only one file in the list, the output will not be a list\n",
    "        session_files = [session_files]\n",
    "    \n",
    "    # output files\n",
    "    probe = get_probe_name(current_session)\n",
    "\n",
    "    if mouse not in axona_refs.keys():\n",
    "        for key in axona_refs.keys():\n",
    "            if key in session_files[0]:\n",
    "                mouse = key\n",
    "            \n",
    "    if reref_channels == 'auto':\n",
    "        reref_channels = tintRef2intan(axona_refs[mouse], \n",
    "                                       tetrode_map, \n",
    "                                       probe)\n",
    "        print('The following reref_channels were chosen: ', reref_channels)\n",
    "        \n",
    "        \n",
    "    pos_filename = output_basename + '.pos'\n",
    "    set_filename = tint_fullpath + '.set'\n",
    "    bin_filename = tint_fullpath + '.bin'\n",
    "    \n",
    "    converted_set_filename = output_basename + '.set'\n",
    "    # Process returned with non-zero exit code\n",
    "    convert_intan_mountainsort(session_files, interpolation=interpolation, whiten=whiten, \n",
    "                               detect_interval=detect_interval,\n",
    "                               detect_sign=detect_sign,  detect_threshold=detect_threshold, \n",
    "                               freq_min=freq_min,\n",
    "                               freq_max=freq_max, mask_threshold=mask_threshold, \n",
    "                               flip_sign=flip_sign,\n",
    "                               software_rereference=software_rereference, \n",
    "                               reref_method=reref_method,\n",
    "                               reref_channels=reref_channels, \n",
    "                               masked_chunk_size=masked_chunk_size,\n",
    "                               mask=mask,\n",
    "                               mask_num_write_chunks=mask_num_write_chunks, \n",
    "                               clip_size=clip_size,\n",
    "                               notch_filter=notch_filter, \n",
    "                               desired_Fs=desired_Fs, \n",
    "                               positionSampleFreq=positionSampleFreq, \n",
    "                               pre_spike_samples=pre_spike_samples, \n",
    "                               post_spike_samples=post_spike_samples, \n",
    "                               rejthreshtail=rejthreshtail, rejstart=rejstart,\n",
    "                               rejthreshupper=rejthreshupper, rejthreshlower=rejthreshlower,\n",
    "                               remove_spike_percentage=remove_spike_percentage, \n",
    "                               remove_outliers=remove_outliers,\n",
    "                               clip_scalar=clip_scalar,\n",
    "                               clip_method=remove_method,\n",
    "                               eeg_channels = eeg_channels,\n",
    "                               num_features=num_features,\n",
    "                               max_num_clips_for_pca=max_num_clips_for_pca,\n",
    "                               self=self)\n",
    "    \n",
    "    print('------------------')\n",
    "print('------finished------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
